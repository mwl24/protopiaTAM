---
title: "Final Model"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(readxl)
library(randomForest)
require(caTools)
library(MASS)
library(caret)
library(class)
library(BBmisc)
library(ggplot2)
```

#Data Cleaning and Variable Selection
```{r}
# select variables and convert to factors
df <- read_excel("data/Alumni-Engagement-Market-Research-Master-List.xlsx")
df <- df %>% dplyr::select(Rank, Q1, Q2, Q3, Q4, Q5, Q6, Q42, Q43, Q44, Q45)
df <- df[-1,]
df <- df %>% mutate_all(funs(factor(.)))
df
```


```{r}
# remove non-collectible variables for prediction purposes
sub_data <- df %>% 
  dplyr::select(Q44, Rank, Q1, Q2, Q3, Q4)
sub_data <- na.omit(sub_data) #remove NAs
sub_data
```

```{r}
# reformat data into quantiative variables
data <- sub_data %>% mutate(spending = ifelse(Q44 == "$80,000 - $100,000", 90000,
                                      ifelse(Q44 == "$60,000 - $80,000", 70000,
                                             ifelse(Q44 == "$40,000 - $60,000", 50000,
                                                    ifelse(Q44 == "$20,000 - $40,000", 30000,
                                                           10000))))) %>% 
  mutate(numRank = ifelse(Rank == "1-20", 10,
                          ifelse(Rank == "21-40", 30,
                                 ifelse(Rank == "41-60", 50,
                                        ifelse(Rank == "61-80", 70,
                                               ifelse(Rank == "81-100", 90,
                                                     150)))))) %>% 
  mutate(pop_size = ifelse(Q2 == "< 10,000", 5000, 
                           ifelse(Q2 == "10,000 - 20,000", 15000,
                                  ifelse(Q2 == "20,000 - 30,000", 250000,
                                         ifelse(Q3 == "30,000 - 40,000", 35000,
                                                ifelse(Q3 == "40,000 - 50,000", 45000,
                                                       75000)))))) %>% 
  mutate(endowment = ifelse(Q3 == "< $500M", 250, 
                            ifelse(Q3 == "$500M - $1B", 750, 
                                   ifelse(Q3 == "$1B - $5B", 2500,
                                          7500)))) %>% 
  mutate(schools = ifelse(Q4 == "1 - 3", 2, 
                          ifelse(Q4 == "4 - 6", 5,
                                 ifelse(Q4 == "7 - 9", 8,
                                        11)))) %>% 
  dplyr::select(spending, numRank, pop_size, endowment, schools)

data
```


#EDA
```{r}
attach(data)
pairs(data)
```

#Models

##Linear Stepwise Regression

```{r}
full_lm <- lm(spending ~., data = data)
step_lm <- stepAIC(full_lm, direction = "both", trace = FALSE)
summary(step_lm)
```

```{r}
# Train a model with k-fold cross-validation
set.seed(24)
train_control <- trainControl(method = "cv", number = 10)
step_model <- train(spending ~., data = data,
                    method = "leapSeq",
                    tuneGrid = data.frame(nvmax = 1:4),
                    trControl = train_control
                    )
step_model$results
step_model$bestTune
summary(step_model$finalModel)
coef(step_model$finalModel, 1)
```

Conducting stepwise regression shows that only `endowment` appears to have a statistically significant relationship with `spending`. 

##Logistic Regression

```{r}
full_logit <- glm(factor(spending, order = TRUE, levels = c(10000, 30000, 50000, 70000, 90000)) ~ ., 
                  data = data, family = "binomial")
step_logit <- stepAIC(full_logit, direction = "both", trace = FALSE)
summary(step_logit)
```

Neither of the coefficients are particularly meaningful in the final model selected by stepwise selection. 

##KNN
```{r}
norm_data <- cbind(data, as.data.frame(lapply(data[2:5], normalize))) # normalize data for standardization across predictors
set.seed(100)
train_ind <- sample(x = nrow(norm_data), size = 0.75 * nrow(norm_data))
test_ind_neg <- -train_ind
training <- norm_data[train_ind, ]
testing <- norm_data[test_ind_neg, ]
train_labels <- norm_data[train_ind, 1]
spending_pred <- knn(train = training, test = testing, cl = train_labels)
table(spending_pred, testing$spending)

```
KNN gives us 100% classification accuracy on the testing data set in this instance, but we will perform cross-validation to find a more robust model and choice for `k`.

```{r}
set.seed(45)
trControl <- trainControl(method = "cv", 
                          number = 10)
fit <- train(factor(spending, order = TRUE, levels = c(10000, 30000, 50000, 70000, 90000)) ~ .,
             method = "knn",
             tuneGrid = expand.grid(k = 1:10),
             trControl = trControl,
             metric = "Accuracy",
             data = data)
fit
```
Classification accuracy approaches 50% with the choice of `k = 3`, which is encouraging given that there are five different response classes.

##Random Forest

```{r}
rf <- randomForest(factor(spending, order = TRUE, levels = c(10000, 30000, 50000, 70000, 90000)) ~ ., 
                   data = data, ntree = 10000)
rf
```
The classification accuracy of the random forest algorithm is relatively low. 

##Linear Discriminant Analysis

```{r}
spending.lda <- lda(factor(spending, order = TRUE, levels = c(10000, 30000, 50000, 70000, 90000)) ~., data = data)
lda.pred <- predict(spending.lda)
table(data$spending, lda.pred$class)
```


##Quadratic Discriminant Analysis
```{r}
spending_qda <- qda(spending ~ schools + numRank + pop_size + schools, data = data)
qda_pred <- predict(spending_qda)
table(data$spending, qda_pred$class)
```

The confusion matrix looks much better than the ones obtained from Random Forest and Linear Discriminant Analysis. We will perform leave-one-out cross-validation to evaluate the robustness of the model.

```{r}
spending_qda_cv <- qda(spending ~ schools + numRank + pop_size + schools, CV = TRUE, data = data)
table(data$spending, spending_qda_cv$class)
```

#Final Model

The best-performing models were multiple linear regression, KNN, and QDA. We will use each of them in turn to get an estimate for spending at each of the top 389 colleges in the United States as ranked in the U.S. News & World Report rankings. This will serve as the basis for our TAM estimate.

```{r}

```


